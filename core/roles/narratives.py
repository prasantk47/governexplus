# Executive Narrative Generator
# Human-readable role governance stories

"""
Executive Narrative Generator for GOVERNEX+.

Transforms data into compelling executive stories:
- Risk reduction narratives
- Implementation progress
- Benchmark positioning
- Audit-ready summaries
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from datetime import datetime
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class NarrativeType(Enum):
    """Types of narratives."""
    EXECUTIVE_SUMMARY = "EXECUTIVE_SUMMARY"
    RISK_REDUCTION = "RISK_REDUCTION"
    IMPLEMENTATION_PROGRESS = "IMPLEMENTATION_PROGRESS"
    BENCHMARK_COMPARISON = "BENCHMARK_COMPARISON"
    AUDIT_SUMMARY = "AUDIT_SUMMARY"
    INCIDENT_RESPONSE = "INCIDENT_RESPONSE"


class AudienceType(Enum):
    """Target audience for narrative."""
    BOARD = "BOARD"
    C_SUITE = "C_SUITE"
    SECURITY = "SECURITY"
    AUDIT = "AUDIT"
    OPERATIONS = "OPERATIONS"


@dataclass
class NarrativeSection:
    """A section within a narrative."""
    title: str
    content: str
    data_points: List[Dict[str, Any]] = field(default_factory=list)
    chart_type: Optional[str] = None  # "bar", "line", "pie", etc.


@dataclass
class ExecutiveNarrative:
    """
    Complete executive narrative.

    Audit-safe, human-readable summary.
    """
    narrative_id: str
    title: str
    narrative_type: NarrativeType
    audience: AudienceType

    # Content
    headline: str = ""
    summary: str = ""
    sections: List[NarrativeSection] = field(default_factory=list)

    # Key metrics
    key_metrics: Dict[str, Any] = field(default_factory=dict)

    # Call to action
    recommendations: List[str] = field(default_factory=list)
    next_steps: List[str] = field(default_factory=list)

    # Metadata
    generated_at: datetime = field(default_factory=datetime.now)
    data_period: str = ""
    generated_by: str = "GOVERNEX+"

    def to_dict(self) -> Dict[str, Any]:
        return {
            "narrative_id": self.narrative_id,
            "title": self.title,
            "type": self.narrative_type.value,
            "audience": self.audience.value,
            "headline": self.headline,
            "summary": self.summary,
            "sections": [
                {
                    "title": s.title,
                    "content": s.content,
                    "data_points": s.data_points,
                }
                for s in self.sections
            ],
            "key_metrics": self.key_metrics,
            "recommendations": self.recommendations,
            "next_steps": self.next_steps,
            "generated_at": self.generated_at.isoformat(),
            "data_period": self.data_period,
        }

    def to_markdown(self) -> str:
        """Convert narrative to markdown format."""
        lines = []
        lines.append(f"# {self.title}")
        lines.append("")
        lines.append(f"**{self.headline}**")
        lines.append("")
        lines.append(self.summary)
        lines.append("")

        for section in self.sections:
            lines.append(f"## {section.title}")
            lines.append("")
            lines.append(section.content)
            lines.append("")

            if section.data_points:
                for dp in section.data_points:
                    lines.append(f"- **{dp.get('label', '')}**: {dp.get('value', '')}")
                lines.append("")

        if self.recommendations:
            lines.append("## Recommendations")
            lines.append("")
            for rec in self.recommendations:
                lines.append(f"- {rec}")
            lines.append("")

        if self.next_steps:
            lines.append("## Next Steps")
            lines.append("")
            for step in self.next_steps:
                lines.append(f"1. {step}")
            lines.append("")

        lines.append("---")
        lines.append(f"*Generated by {self.generated_by} on {self.generated_at.strftime('%Y-%m-%d %H:%M')}*")

        return "\n".join(lines)


class RoleNarrativeGenerator:
    """
    Generates executive narratives for role governance.

    Transforms metrics into compelling stories.
    """

    def __init__(self):
        """Initialize generator."""
        self._counter = 0

    def generate_risk_reduction_narrative(
        self,
        baseline_metrics: Dict[str, Any],
        current_metrics: Dict[str, Any],
        audience: AudienceType = AudienceType.C_SUITE
    ) -> ExecutiveNarrative:
        """
        Generate risk reduction narrative.

        Args:
            baseline_metrics: Metrics at baseline
            current_metrics: Current metrics
            audience: Target audience

        Returns:
            ExecutiveNarrative with risk reduction story
        """
        self._counter += 1
        narrative_id = f"NAR-RISK-{datetime.now().strftime('%Y%m%d')}-{self._counter}"

        # Calculate reductions
        baseline_toxic = baseline_metrics.get("toxic_roles", 0)
        current_toxic = current_metrics.get("toxic_roles", 0)
        toxic_reduction = ((baseline_toxic - current_toxic) / max(baseline_toxic, 1)) * 100

        baseline_unused = baseline_metrics.get("unused_permissions", 0)
        current_unused = current_metrics.get("unused_permissions", 0)
        unused_reduction = ((baseline_unused - current_unused) / max(baseline_unused, 1)) * 100

        baseline_sod = baseline_metrics.get("sod_violations", 0)
        current_sod = current_metrics.get("sod_violations", 0)
        sod_reduction = ((baseline_sod - current_sod) / max(baseline_sod, 1)) * 100

        baseline_risk = baseline_metrics.get("risk_score", 100)
        current_risk = current_metrics.get("risk_score", baseline_risk)
        risk_reduction = ((baseline_risk - current_risk) / max(baseline_risk, 1)) * 100

        benchmark_percentile = current_metrics.get("benchmark_percentile", 50)

        # Generate headline
        if risk_reduction >= 50:
            headline = f"Access Risk Reduced by {risk_reduction:.0f}% Through AI-Driven Role Redesign"
        elif risk_reduction >= 25:
            headline = f"Significant Risk Reduction: {risk_reduction:.0f}% Lower Access Risk"
        else:
            headline = f"Ongoing Risk Reduction: {risk_reduction:.0f}% Improvement Achieved"

        # Generate summary
        summary = (
            f"Since implementing AI-driven role governance, we have reduced toxic roles by "
            f"{toxic_reduction:.0f}%, eliminated {unused_reduction:.0f}% of unused permissions, "
            f"and resolved {sod_reduction:.0f}% of segregation of duties conflicts. "
            f"Our access risk posture is now better than {benchmark_percentile:.0f}% of peer organizations."
        )

        # Build sections
        sections = []

        # Risk reduction section
        sections.append(NarrativeSection(
            title="Risk Reduction Summary",
            content=(
                f"The AI-driven role redesign initiative has delivered measurable risk reduction "
                f"across all key metrics. Critical SoD conflicts have been eliminated before "
                f"they could cause audit issues or enable fraud."
            ),
            data_points=[
                {"label": "Toxic Role Reduction", "value": f"{toxic_reduction:.0f}%"},
                {"label": "Unused Permission Removal", "value": f"{unused_reduction:.0f}%"},
                {"label": "SoD Conflict Resolution", "value": f"{sod_reduction:.0f}%"},
                {"label": "Overall Risk Score Reduction", "value": f"{risk_reduction:.0f}%"},
            ],
            chart_type="bar",
        ))

        # Benchmark section
        sections.append(NarrativeSection(
            title="Industry Positioning",
            content=(
                f"Compared to industry peers, our role governance maturity now ranks in the "
                f"{benchmark_percentile:.0f}th percentile. This represents a significant "
                f"improvement from our baseline position."
            ),
            data_points=[
                {"label": "Industry Benchmark", "value": f"{benchmark_percentile:.0f}th percentile"},
            ],
        ))

        # Business impact section
        audit_issues_avoided = max(1, int(sod_reduction * 0.3))
        sections.append(NarrativeSection(
            title="Business Impact",
            content=(
                f"The proactive approach to access risk has prevented an estimated "
                f"{audit_issues_avoided} potential audit findings. Controls are now evaluated "
                f"continuously rather than periodically, enabling real-time risk management."
            ),
            data_points=[
                {"label": "Audit Issues Prevented", "value": str(audit_issues_avoided)},
                {"label": "Control Evaluation", "value": "Continuous"},
            ],
        ))

        # Build recommendations
        recommendations = []
        if current_toxic > 0:
            recommendations.append(
                f"Continue toxic role remediation to eliminate remaining {current_toxic} toxic roles"
            )
        if current_sod > 0:
            recommendations.append(
                f"Address remaining {current_sod} SoD conflicts through role splitting or mitigation"
            )
        if benchmark_percentile < 75:
            recommendations.append(
                "Target 75th percentile benchmark positioning in next quarter"
            )

        # Build next steps
        next_steps = [
            "Maintain continuous control monitoring",
            "Expand AI-driven role redesign to additional business processes",
            "Implement predictive risk forecasting",
        ]

        return ExecutiveNarrative(
            narrative_id=narrative_id,
            title="Role Governance Risk Reduction Report",
            narrative_type=NarrativeType.RISK_REDUCTION,
            audience=audience,
            headline=headline,
            summary=summary,
            sections=sections,
            key_metrics={
                "toxic_reduction": toxic_reduction,
                "unused_reduction": unused_reduction,
                "sod_reduction": sod_reduction,
                "risk_reduction": risk_reduction,
                "benchmark_percentile": benchmark_percentile,
            },
            recommendations=recommendations,
            next_steps=next_steps,
        )

    def generate_implementation_progress_narrative(
        self,
        phase: str,
        completed_items: List[str],
        pending_items: List[str],
        metrics: Dict[str, Any],
        audience: AudienceType = AudienceType.C_SUITE
    ) -> ExecutiveNarrative:
        """
        Generate implementation progress narrative.

        Args:
            phase: Current implementation phase
            completed_items: Completed milestones
            pending_items: Pending milestones
            metrics: Current metrics
            audience: Target audience

        Returns:
            ExecutiveNarrative with progress story
        """
        self._counter += 1
        narrative_id = f"NAR-PROG-{datetime.now().strftime('%Y%m%d')}-{self._counter}"

        total_items = len(completed_items) + len(pending_items)
        completion_pct = len(completed_items) / max(total_items, 1) * 100

        # Generate headline
        headline = f"Role Transformation: {completion_pct:.0f}% Complete - {phase}"

        # Generate summary
        summary = (
            f"The AI-assisted role transformation project is {completion_pct:.0f}% complete. "
            f"We have successfully completed {len(completed_items)} milestones with "
            f"{len(pending_items)} remaining. The project remains on track to deliver "
            f"the targeted risk reduction."
        )

        # Build sections
        sections = []

        # Completed items
        if completed_items:
            sections.append(NarrativeSection(
                title="Completed Milestones",
                content=(
                    f"The following {len(completed_items)} milestones have been successfully completed:"
                ),
                data_points=[
                    {"label": item, "value": "✓ Complete"}
                    for item in completed_items
                ],
            ))

        # Pending items
        if pending_items:
            sections.append(NarrativeSection(
                title="Upcoming Milestones",
                content=(
                    f"The following {len(pending_items)} milestones are in progress or pending:"
                ),
                data_points=[
                    {"label": item, "value": "→ Pending"}
                    for item in pending_items
                ],
            ))

        # Early results
        roles_redesigned = metrics.get("roles_redesigned", 0)
        risks_mitigated = metrics.get("risks_mitigated", 0)

        sections.append(NarrativeSection(
            title="Early Results",
            content=(
                f"Even before project completion, we are seeing measurable improvements. "
                f"{roles_redesigned} roles have been redesigned based on AI recommendations, "
                f"and {risks_mitigated} risks have been mitigated."
            ),
            data_points=[
                {"label": "Roles Redesigned", "value": str(roles_redesigned)},
                {"label": "Risks Mitigated", "value": str(risks_mitigated)},
            ],
        ))

        return ExecutiveNarrative(
            narrative_id=narrative_id,
            title=f"Role Transformation Progress Report - {phase}",
            narrative_type=NarrativeType.IMPLEMENTATION_PROGRESS,
            audience=audience,
            headline=headline,
            summary=summary,
            sections=sections,
            key_metrics={
                "phase": phase,
                "completion_pct": completion_pct,
                "completed_count": len(completed_items),
                "pending_count": len(pending_items),
            },
            next_steps=pending_items[:3] if pending_items else [],
        )

    def generate_audit_summary_narrative(
        self,
        audit_period: str,
        findings: List[Dict[str, Any]],
        controls_evaluated: int,
        controls_passed: int,
        audience: AudienceType = AudienceType.AUDIT
    ) -> ExecutiveNarrative:
        """
        Generate audit-ready summary narrative.

        Args:
            audit_period: Period covered
            findings: Audit findings
            controls_evaluated: Number of controls checked
            controls_passed: Number passed
            audience: Target audience

        Returns:
            ExecutiveNarrative for auditors
        """
        self._counter += 1
        narrative_id = f"NAR-AUD-{datetime.now().strftime('%Y%m%d')}-{self._counter}"

        pass_rate = controls_passed / max(controls_evaluated, 1) * 100
        critical_findings = sum(1 for f in findings if f.get("severity") == "CRITICAL")
        high_findings = sum(1 for f in findings if f.get("severity") == "HIGH")

        # Generate headline
        if critical_findings == 0 and high_findings == 0:
            headline = f"Clean Audit: {pass_rate:.0f}% Control Pass Rate"
        elif critical_findings == 0:
            headline = f"Audit Summary: {high_findings} High-Priority Items Identified"
        else:
            headline = f"Audit Summary: {critical_findings} Critical Items Require Attention"

        # Generate summary
        summary = (
            f"During the audit period ({audit_period}), {controls_evaluated} controls were "
            f"evaluated with {controls_passed} ({pass_rate:.0f}%) passing. "
            f"{len(findings)} total findings were identified, including "
            f"{critical_findings} critical and {high_findings} high-priority items."
        )

        # Build sections
        sections = []

        # Control summary
        sections.append(NarrativeSection(
            title="Control Evaluation Summary",
            content=(
                f"Continuous control monitoring evaluated {controls_evaluated} controls "
                f"throughout the period. Evidence was automatically collected and preserved "
                f"for each control evaluation."
            ),
            data_points=[
                {"label": "Controls Evaluated", "value": str(controls_evaluated)},
                {"label": "Controls Passed", "value": str(controls_passed)},
                {"label": "Pass Rate", "value": f"{pass_rate:.0f}%"},
            ],
        ))

        # Findings summary
        if findings:
            sections.append(NarrativeSection(
                title="Findings Summary",
                content=(
                    f"A total of {len(findings)} findings were identified and documented. "
                    f"Remediation plans have been established for all critical and high-priority items."
                ),
                data_points=[
                    {"label": f.get("title", "Finding"), "value": f.get("severity", "MEDIUM")}
                    for f in findings[:10]
                ],
            ))

        # Evidence collection
        sections.append(NarrativeSection(
            title="Evidence Collection",
            content=(
                "All control evaluations include automatically generated evidence packages "
                "with timestamps, data sources, and evaluation results. Evidence is retained "
                "according to the configured retention policy."
            ),
            data_points=[
                {"label": "Evidence Retention", "value": "365 days"},
                {"label": "Evidence Format", "value": "JSON + Screenshots"},
            ],
        ))

        return ExecutiveNarrative(
            narrative_id=narrative_id,
            title=f"Access Control Audit Summary - {audit_period}",
            narrative_type=NarrativeType.AUDIT_SUMMARY,
            audience=audience,
            headline=headline,
            summary=summary,
            sections=sections,
            key_metrics={
                "controls_evaluated": controls_evaluated,
                "controls_passed": controls_passed,
                "pass_rate": pass_rate,
                "critical_findings": critical_findings,
                "high_findings": high_findings,
            },
            data_period=audit_period,
        )

    def generate_one_liner(
        self,
        baseline_metrics: Dict[str, Any],
        current_metrics: Dict[str, Any]
    ) -> str:
        """
        Generate one-line executive summary.

        "Since redesigning roles using AI-driven usage analysis, we reduced
        toxic roles by 62%, cut unused permissions by 48%, and eliminated
        critical SoD risks before go-live. Our access risk posture is now
        better than 71% of peer organizations."
        """
        baseline_toxic = baseline_metrics.get("toxic_roles", 10)
        current_toxic = current_metrics.get("toxic_roles", 0)
        toxic_reduction = ((baseline_toxic - current_toxic) / max(baseline_toxic, 1)) * 100

        baseline_unused = baseline_metrics.get("unused_permissions", 100)
        current_unused = current_metrics.get("unused_permissions", 0)
        unused_reduction = ((baseline_unused - current_unused) / max(baseline_unused, 1)) * 100

        baseline_sod = baseline_metrics.get("critical_sod", 10)
        current_sod = current_metrics.get("critical_sod", 0)

        benchmark_percentile = current_metrics.get("benchmark_percentile", 50)

        sod_text = "eliminated critical SoD risks before go-live" if current_sod == 0 else \
            f"reduced critical SoD conflicts by {((baseline_sod - current_sod) / max(baseline_sod, 1) * 100):.0f}%"

        return (
            f"Since redesigning roles using AI-driven usage analysis, we reduced "
            f"toxic roles by {toxic_reduction:.0f}%, cut unused permissions by {unused_reduction:.0f}%, "
            f"and {sod_text}. Our access risk posture is now better than "
            f"{benchmark_percentile:.0f}% of peer organizations."
        )
